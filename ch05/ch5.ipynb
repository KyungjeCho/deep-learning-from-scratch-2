{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee53625",
   "metadata": {},
   "source": [
    "<h1> ch5 순환 신경망(RNN) </h1>\n",
    "\n",
    "<p>\n",
    "    흐림이 단방향인 신경망을 피드포워드라고 말한다. 피드포워드 신경망은 구성이 단순하다. 많은 문제에 응용할 수 있다. 하지만 시계열 데이터를 잘 다루지 못한다. 정확히 단순한 피드포워드 신경망에서 시계열 데이터의 성질을 충분히 학습할 수 없다. 순환 신경망(RNN)은 피드포워드 신경망의 문제점을 훌륭하게 해결해준다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55479bfc",
   "metadata": {},
   "source": [
    "<h2> 5.1 확률과 언어 모델 </h2>\n",
    "\n",
    "<h3> 5.1.1 word2vec을 확률 관점에서 바라보다 </h3>\n",
    "\n",
    "<p> \n",
    "    word2vec의 CBOW 모델에서 $ w_1, w_2, \\cdots, w_t $ 라는 단어열로 표현되는 말뭉치가 있다고 가정한다. 그리고 t번째 단어를 '타깃', 그 전후 단어 ( t-1 번, t+1 번)을 '맥락'으로 취급한다. CBOW 모델은 $w_{t-1}$과 $w_{t+1}$로부터 타깃 $w_{t}$ 를 추측하는 일을 수행한다. $w_{t-1}$과 $w_{t+1}$이 주어졌을 경우 $w_{t}$가 될 확률을 나타낸다.\n",
    "    $$\n",
    "        P(w_t | w_{t-1}, w_{t+1})\n",
    "    $$\n",
    "    CBOW 모델은 $w_{t-1}$과 $w_{t+1}$이 주어졌을 때 $w_{t}$가 일어날 확률을 모델링한다. 윈도우 크기가 1일 경우이다. 지금까지는 전후, 좌우 대칭으로 맥락을 생각했다. 이번에는 왼쪽 윈도우만 한정한다. 왼쪽 두 단어만을 맥락으로 확률을 나타낸다\n",
    "    $$\n",
    "        P(w_t | w_{t-2}, w_{t-1})\n",
    "    $$\n",
    "    이 확률로 CBOW 모델의 손실 함수를 교차 엔트로피 오차에 의해 유도할 수 있다. \n",
    "    $$\n",
    "        L = - logP(w_t | w_{t-2}. w_{t-1})\n",
    "    $$\n",
    "    CBOW 모델의 학습으로 손실 함수를 최소화하는 가중치 매개변수를 찾고, 가중치 매개변수가 발견되면 CBOW 모델은 맥락으로부터 타깃을 더 정확하게 추측할 수 있다. CBOW 모델을 학습시키는 목적은 맥락으로부터 타깃을 정확하게 추측하는 것이다. 학습을 진행하면 단어의 의미가 인코딩된 '단어의 분산 표현'을 얻는다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284e4c0",
   "metadata": {},
   "source": [
    "<h3> 5.1.2 언어 모델 </h3>\n",
    "\n",
    "<p>\n",
    "    언어 모델은 단어 나열에 확률을 부여한다. 특정한 단어의 시퀀스가 일어날 가능성이 어느 정도인지 확률로 평가한다. 언어 모델은 다양하게 응용할 수 있다. 기계 번역과 음성 인식이 대표적인 예이다. 음성 인식의 경우, 사람의 음성으로부터 몇개의 문장을 후보로 생성하고, 언어 모델을 사용하여 문장으로써 자연스러운지 기준을 순서로 매길 수 있다. 언어 모델은 새로운 문장을 생성하는 용도로도 이용할 수 있다. 언어 모델은 단어 순서의 자연스러움을 확률적으로 평가하기 때문이다. 그 확률분포에 따라 다음으로 적합한 단어를 샘플링할 수 있다. \n",
    "</p>\n",
    "<p>\n",
    "    언어 모델을 수식으로 설명한다. $w_1, \\cdots, w_m$ 이라는 m개 단어로 된 문장. 이 때 단어가 $w_1, \\cdots, w_m$ 이 순서로 출현할 확률을 $ P(w_1, \\cdots, w_m) $. 이 확률은 동시에 일어날 확률이므로 동시 확률. $P(w_1, \\cdots, w_m)$은 사후 확률을 사용하여 분햏하여 쓸 수 있다\n",
    "    $$\n",
    "        P(w_1, \\cdots, w_m) = P(w_m|w_1, \\cdots, w_{m-1}) \\times P(w_{m-1}|w_1, \\cdots, w_{m-1}) \\\n",
    "                                \\times \\cdots \\times P(w_3|,w_1, w_2) \\times P(w_2| w_1) \\times \\\n",
    "                                P(w_1) \\\\\n",
    "                            = \\prod_{t=1}^{m} P(w_t| w_1,\\cdots, w_{t-1})\n",
    "    $$\n",
    "    동시 확률은 사후 확률의 총곱으로 나타낼수 있다. 위 결과는 확률의 곱셈정리로부터 유도할 수 있다. 확률의 곱셈정리는 다음 식으로 표현된다.\n",
    "    $$\n",
    "        P(A, B) = P(A|B)P(B) \n",
    "    $$\n",
    "    위 식의 의미는 'A와 B가 모두 일어날 확률 P(A, B)'는 'B가 일어날 확률 P(B)'와 'B가 일어난 후 A가 일어날 확률 P(A|B)'를 곱한 값과 같다. 이 곱셈정리를 사용하면 m개 단어의 동시 확률 $P(w_1, \\cdots, w_m)$을 사후 확률로 나타낼 수 있다. \n",
    "    $$\n",
    "        P(\\underbrace{w_1, \\cdots, w_{m-1}}_{A}, w_m) = P(A, w_m) = P(w_m|A)P(A) \\\\\n",
    "        P(A) = P(\\underbrace{w_1, \\cdots, w_{m-2}}_{A'}, w_{m-1}) = P(A', w_{m-1}) = \\\n",
    "                                                        P(w_{m-1}|A')P(A')\n",
    "    $$\n",
    "    단어의 동시 확률을 차례로 하나씩 줄여가면서 매번 사후 확률로 분해한다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfa9f6",
   "metadata": {},
   "source": [
    "<h3> 5.1.3 CBOW 모델을 언어 모델로? </h3>\n",
    "\n",
    "<p>\n",
    "    word2vec의 CBOW 모델을 언어 모델에 적용하기 위해 맥락의 크기를 특정 값으로 한정하여 근사적으로 표현할 수 있다. \n",
    "    $$\n",
    "        P(w_1, \\cdots, w_m) \\prod_{t=1}^m P(w_t|w_1, \\cdots, w_{t-1}) \\approx \\prod_{t=1}^m P(w_t|w_{t-2}, w_{t-1})\n",
    "    $$\n",
    "    여기서는 맥락을 왼쪽 2개의 단어로 한정한다. CBOW 모델에 따라 근사적으로 나타난다. 물론 맥락의 크기는 임의로 설정할 수 있다. 하지만, 결국 특정 길이로 '고정'된다. 예를 들어, <br />\n",
    "    'Tom was watching TV in his room. Mary came into the room. Mary said hi to [?]' <br />\n",
    "    예문있다고 가정한다. [?]로부터 18번째 앞에서 나오는 \"Tom\"을 기억해야 [?]를 추측할 수 있다. 하지만 맥락의 크기가 10이면 Tom을 기억하지 못할 것이다. 물론 맥락 크기는 얼마든지 키울 수 있다. 하지만 CBOW 모델에서는 맥락 안의 단어 순서가 무시된다는 한계가 있다. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    CBOW 모델의 은닉층에서는 단어 벡터들이 더해지므로 맥락의 단어 순서는 무시된다. (you, say)와 (say, you)라는 맥락을 똑같이 취급한다. 맥락의 단어 순서도 고려한 모델이 바람직하다. 맥락의 단어 벡터를 은닉층에서 연결하는 방식을 생각할 수 있다. 신경 확률론적 언어 모델에서 제안한 모델은 이 방식을 취하지만, 맥락의 크기에 비례하면 가중치 매개변수도 늘어난다. RNN은 맥락이 아무리 길더라도 그 맥락의 정보를 기억하는 매커니즘을 갖추고 있다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87cbe2",
   "metadata": {},
   "source": [
    "<h2> 5.2 RNN이란 </h2>\n",
    "\n",
    "<p>\n",
    "    RNN의 'Recurrent'는 라틴어에서 온 말로, '몇 번이나 반복해서 일어나는 일'을 뜻한다. 우리말로 '재발한다', '주기적으로 일어난다', '순환한다' 등으로 번역된다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537ca6e",
   "metadata": {},
   "source": [
    "<h3> 5.2.1 순환하는 신경망 </h3>\n",
    "\n",
    "<p>\n",
    "    순환한다는 반복해서 되돌아감을 의미한다. 어느 한 지점에서 시작하여, 시간이 지나 다시 원래 장소로 돌아오는 것, 그리고 이 과정을 반복하는 것이 '순환'이다. 순환하기 위해서 '닫힌 경로'가 필요하다. RNN의 특징은 순환하는 경로(닫힌 경로)가 있다는 것이다. 순환 경로에 따라 데이터는 끊임없이 순환할 수 있다. 입력으로 $ \\textbf{x}_t $ 를 입력받는데, t는 시각을 뜻한다. 시계열 데이터 $ (\\textbf{x}_0, \\textbf{x}_1, \\cdots, \\textbf{x}_t, \\cdots) $ 가 RNN 계층에 입력됨을 표현한다. 그리고 입력에 대응하여 $ (\\textbf{h}_0, \\textbf{h}_1, \\cdots, \\textbf{h}_t, \\cdots) $ 가 출력된다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59b650",
   "metadata": {},
   "source": [
    "<h3> 5.2.2 순환 구조 펼치기 </h3>\n",
    "\n",
    "<p>\n",
    "    RNN의 순환 구조는 닫힌 경로가 존재하므로, 이것을 풀어서 설명한다면 이해하기 쉬어질 것이다. 시간에 따라 오른쪽으로 성장하는 긴 신경망으로 설명할 수 있다. 오른쪽 축은 시간순서이다. 물론, 오른쪽에서 등장하는 RNN 계층은 모두 같은 계층이다. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    각 시각의 RNN 계층은 입력과 1 시각 전의 RNN 계층으로 부터의 출력을 입력으로 받는다. 두 정보를 바탕으로 현 시각의 출력을 계산한다.\n",
    "    $$\n",
    "        \\textbf{h}_t = tanh(\\textbf{h}_{t-1} \\textbf{W}_{\\textbf{h}} + \\textbf{x}_t\\textbf{W}_{\\textbf{x}} + \\textbf{b})\n",
    "    $$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe5c7a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# x = np.linspace(-np.pi, np.pi, 201)\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "plt.plot(x, np.tanh(x))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('tanh(x)')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd6dff",
   "metadata": {},
   "source": [
    "<p> 언뜻 보면 하이퍼볼릭 탄젠트 함수와 시그모이드 함수와 비슷하게 보인다. </p>\n",
    "\n",
    "<p>\n",
    "    RNN에는 가중치가 2개 있다. 하나는 입력 $\\textbf{x}$를 출력 $\\textbf{h}$로 변환하기 위한 $\\textbf{W}_{\\textbf{x}}$이고, 다른 하나는 1개의 RNN 출력을 다음 시각의 출력으로 변환하기 위한 가중치 $\\textbf{W}_{\\textbf{h}}$이다. 물론 변향 $\\textbf{b}$도 있다. 각 가중치의 행렬 곱을 계산하고, 그 합을 tanh 함수 (하이퍼볼릭 탄젠트)를 이용해 반환한다. 결과로 시각 t의 출력 $\\textbf{h}_t$가 출력된다. 이 출력은 다음 계층을 향해 출력되는 동시에 RNN 계층 자기 자신에게도 출력한다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d40e3",
   "metadata": {},
   "source": [
    "<h3> 5.2.3 BPTT </h3>\n",
    "<p>\n",
    "    순환 구조를 펼친 후의 RNN은 오차역전파법을 적용할 수 있다. 먼저 순전파를 수행하고, 이어서 역전파를 수행하여 원하는 기울기를 구할 수 있다. 여기서 오차역전파법은 '시간 방향으로 펼친 신경망의 오차역전파법'이란 뜻으로 BRTT(Backpropagation Through Time)이라고 한다. 이 BRTT로 RNN을 학습할 수 있을 것 같지만 문제가 하나 있다. 긴 시계열 데이터를 학습할 때 시계열 데이터의 시간 크기가 커지는 것에 비례하여 BRTT가 소비하는 컴퓨팅 자원도 증가하기 때문이다. 그리고 시간 크기가 커지면 역전파 시의 기울기가 불안정해진다. 매 시각 RNN 계층의 중간 데이터 (hidden state vector)를 메모리에 유지해두어야 하기 때문이다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946a7f1",
   "metadata": {},
   "source": [
    "<h3> 5.2.4 Truncated BPTT </h3>\n",
    "\n",
    "<p>\n",
    "    큰 시계열 데이터를 취급할 때는 흔히 신경망 연결을 적당한 길이로 '끊는다'. 시간축 방향으로 너무 길어진 신경망을 적당한 지점에서 잘라내어 작은 신경망 여러 개로 만든다는 아이디어다. Truncated BPTT 에서는 신경망을 끊지만, 제대로 구현할려면 역전파의 연결만 끊어야 한다. 계층이 늘어서더라도 오차역전파법으로 기울기를 계산할 수 있다. 하지만 너무 길면 계산량과 메모리 사용량에 문제가 생기고, 계층이 길어지면 신경망을 하나 통과할 때마다 기울기 값이 조금씩 작아져서. 이전 시각 t까지 역전파되기 전에 0이 되어 소멸할 수 있다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcdbc0",
   "metadata": {},
   "source": [
    "<h3> 5.2.5 Truncated BPTT의 미니배치 학습 </h3>\n",
    "\n",
    "<p>\n",
    "    지금까지는 미니배치 수 1일 경우 해당한다. 미니배치 학습을 위해 데이터를 순서대로 입력해야 한다. 길이가 1000인 시계열 데이터에 대해서, 시각의 길이를 10개 단위로 잘라 Truncated BPTT로 학습하는 경우를 설명한다. 만약 미니배치 수를 두 개로 구성하여 학습한다면, 첫 미니배치는 처음부터 순서대로 데이터를 제공한다. 두번째 미니배치 때는 500번째의 데이터를 시작 위치로 정한다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8024d3",
   "metadata": {},
   "source": [
    "<h2> 5.3 RNN 구현 </h2>\n",
    "\n",
    "<h3> 5.3.1 RNN 계층 구현 </h3>\n",
    "\n",
    "<p>\n",
    "    $$\n",
    "        \\textbf{h}_t = tanh(\\textbf{h}_{t-1} \\textbf{W}_{\\textbf{h}} + \\textbf{x}_t \\textbf{W}_{\\textbf{x}} + \\textbf{x})\n",
    "    $$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6659be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f8184",
   "metadata": {},
   "source": [
    "<h3> 5.3.2 Time RNN 계층 구현 </h3>\n",
    "\n",
    "<p>\n",
    "    Time RNN 계층은 T개의 RNN 계층으로 구성된다. Time RNN 계층은 RNN 계층 T개를 연결한 신경망이다. RNN 계층의 은닉 상태 \\textbf{h}를 인스턴스 변수로 유지한다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea45784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = Npne, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh) \n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1807fcb",
   "metadata": {},
   "source": [
    "<h2> 5.4 시계열 데이터 처리 계층 구현 </h2>\n",
    "\n",
    "<p>\n",
    "    RNN을 사용한 '언어 모델'을 구현한다. RNNLM이라고 한다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ef2af",
   "metadata": {},
   "source": [
    "<h3> 5.4.1 RNNLM의 전체 그림 </h3>\n",
    "\n",
    "<p>\n",
    "    첫 번째 층은 Embedding 계층이다. 이 계층은 단어 ID를 단어의 분산 표현(단어 벡터)으로 변환한다. 그리고 분산 표현이 다음 계층인 RNN 계층으로 입력된다. RNN 계층은 은닉 상태를 다음 층으로 출력하고 동시에, 다음 시각의 RNN 계층으로 출력한다. RNN 계층 위로 은닉 상태는 Affine 계층을 거쳐 Softmax 계층으로 전해진다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d13fbd5",
   "metadata": {},
   "source": [
    "<h3> 5.4.2 Time 계층 구현 </h3>\n",
    "\n",
    "<p>\n",
    "    시계열 데이터를 한꺼번에 처리하는 계층을 Time RNN이라는 이름의 계층으로 구현했다. 시계열 데이터를 한꺼번에 처리하는 계층을 Time Embedding, Time Affine 형태의 이름으로 구현한다. \n",
    "</p>\n",
    "<p>\n",
    "    Softmax 계층을 구현할 때는 손실 오차를 구하는 Cross Entropy Error 계층도 함께 구현한다. Time Softmax with Loss 계층으로 구현한다. T개의 Softmax with Loss 계층 각각이 손실을 산출한다. 손실들을 합산해 평균한 값이 최종 손실이 된다.\n",
    "    $$\n",
    "        L = \\frac{1}{T} ( L_0 + L_1 + \\cdots + L_{T-1})\n",
    "    $$\n",
    "    Softmax with Loss 계층은 미니배치에 해당하는 손실의 평균을 구한다. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699be83",
   "metadata": {},
   "source": [
    "<h2> 5.5 RNNLM 학습과 평가 </h2>\n",
    "\n",
    "<h3> 5.5.1 RNNLM 구현 </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae48cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9bcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grad += layer.grads\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backwrad(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189f97b",
   "metadata": {},
   "source": [
    "<h3> 5.5.2 언어 모델의 평가 </h3>\n",
    "\n",
    "<p>\n",
    "     언어 모델은 주어진 과거 단어로부터 다음에 출현한 단어의 확률분포를 출력한다. 언어 모델의 예측 성능을 평가하는 척도로 퍼플렉서티를 자주 이용한다. 퍼플렉서티는 간단히 말하면 '확률의 역수'이다. 퍼플렉서티는 작을수록 좋다는 것이다. 좋은 모델의 퍼플렉서티가 1.25라면 추측할 단어의 후보가 1개로 좁혀진다는 것이다. 나쁜 모델의 퍼플렉서티가 5라면 추측할 단어의 후보가 5개나 있다는 것이다. 입력 데이터가 여러 개일 때는 다음 공식에 따라 계산된다.\n",
    "    $$\n",
    "        L = - \\frac{1}{N} \\sum_{n}\\sum_{k} t_{nk} log y_{nk} \\\\\n",
    "        perplexity = e^L\n",
    "    $$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042b971",
   "metadata": {},
   "source": [
    "<h3> 5.5.3 RNNLM의 학습 코드 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f4414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 18351320743406280232394167380846239073115136065536.00\n",
      "| 에폭 2 | 퍼플렉서티 9256382108814505490736776727373004499125796864.00\n",
      "| 에폭 3 | 퍼플렉서티 496942099130522721221771010804038176182632448.00\n",
      "| 에폭 4 | 퍼플렉서티 203490042657186287535729253889065774609334272.00\n",
      "| 에폭 5 | 퍼플렉서티 90149777448726279163994660835049369482821632.00\n",
      "| 에폭 6 | 퍼플렉서티 65174552888102622032331861249780153273286656.00\n",
      "| 에폭 7 | 퍼플렉서티 45369971780577645450430018772717214871060480.00\n",
      "| 에폭 8 | 퍼플렉서티 38848406570141817446339414068893652027965440.00\n",
      "| 에폭 9 | 퍼플렉서티 21848729405106457415613845913942513776852992.00\n",
      "| 에폭 10 | 퍼플렉서티 26511859757883776668571950028592306630688768.00\n",
      "| 에폭 11 | 퍼플렉서티 18002509723458987553960645086471163505278976.00\n",
      "| 에폭 12 | 퍼플렉서티 25184751604661758800821516979302031498936320.00\n",
      "| 에폭 13 | 퍼플렉서티 20978451595311525096338298732098381171130368.00\n",
      "| 에폭 14 | 퍼플렉서티 21856185168964884199254398593037112426102784.00\n",
      "| 에폭 15 | 퍼플렉서티 19086326255016436204081556563348129474150400.00\n",
      "| 에폭 16 | 퍼플렉서티 14208750966650606325002132082851039559024640.00\n",
      "| 에폭 17 | 퍼플렉서티 11428513970442021766935511224346858628317184.00\n",
      "| 에폭 18 | 퍼플렉서티 8926273720475105351115136877688508725067776.00\n",
      "| 에폭 19 | 퍼플렉서티 9387937936280027626254331733429289373138944.00\n",
      "| 에폭 20 | 퍼플렉서티 10284885206909503483023475644574112753385472.00\n",
      "| 에폭 21 | 퍼플렉서티 9381848982790118392007101399751671182000128.00\n",
      "| 에폭 22 | 퍼플렉서티 6136666160136192619076794368074129323589632.00\n",
      "| 에폭 23 | 퍼플렉서티 4178775739587141978283059238041036374671360.00\n",
      "| 에폭 24 | 퍼플렉서티 4827910498946675962806847277676829863837696.00\n",
      "| 에폭 25 | 퍼플렉서티 4153699306909715492926396384951833418792960.00\n",
      "| 에폭 26 | 퍼플렉서티 4244489913784612151867686667183732559970304.00\n",
      "| 에폭 27 | 퍼플렉서티 2712894266666255557176411806766830012334080.00\n",
      "| 에폭 28 | 퍼플렉서티 2554038390647508425025674813957111344529408.00\n",
      "| 에폭 29 | 퍼플렉서티 1710946663621453497979753617780944400285696.00\n",
      "| 에폭 30 | 퍼플렉서티 994422055753585668743585321708730693189632.00\n",
      "| 에폭 31 | 퍼플렉서티 1093648167978829900978496216225470138548224.00\n",
      "| 에폭 32 | 퍼플렉서티 583255501273319281176356060633217688928256.00\n",
      "| 에폭 33 | 퍼플렉서티 654170738188134619493357841936155974565888.00\n",
      "| 에폭 34 | 퍼플렉서티 361420783376048451821475773720436806778880.00\n",
      "| 에폭 35 | 퍼플렉서티 248988136359073655220990892147336154185728.00\n",
      "| 에폭 36 | 퍼플렉서티 113388314145783489749356573689272147640320.00\n",
      "| 에폭 37 | 퍼플렉서티 67727982638122711751744805433298091245568.00\n",
      "| 에폭 38 | 퍼플렉서티 34731485693391134779346478491970406711296.00\n",
      "| 에폭 39 | 퍼플렉서티 17359637087161762762731987761644567527424.00\n",
      "| 에폭 40 | 퍼플렉서티 7474576207620952435053244362450834292736.00\n",
      "| 에폭 41 | 퍼플렉서티 7591551524823651103128465231993397837824.00\n",
      "| 에폭 42 | 퍼플렉서티 1938174752262428478270282059269057544192.00\n",
      "| 에폭 43 | 퍼플렉서티 815207510297984276307235061828140662784.00\n",
      "| 에폭 44 | 퍼플렉서티 458080525998402939240107990797892190208.00\n",
      "| 에폭 45 | 퍼플렉서티 203588805759186641962964857687757553664.00\n",
      "| 에폭 46 | 퍼플렉서티 145362505224740895035724731193059442688.00\n",
      "| 에폭 47 | 퍼플렉서티 56223323052548799951448650474789535744.00\n",
      "| 에폭 48 | 퍼플렉서티 15829577673927787640368864908095258624.00\n",
      "| 에폭 49 | 퍼플렉서티 8823596127261386814786428890809106432.00\n",
      "| 에폭 50 | 퍼플렉서티 4457841224734733329136028600336646144.00\n",
      "| 에폭 51 | 퍼플렉서티 1562416767469581837017318460932227072.00\n",
      "| 에폭 52 | 퍼플렉서티 617572621666420784351044073093595136.00\n",
      "| 에폭 53 | 퍼플렉서티 196070737656939565223859184493133824.00\n",
      "| 에폭 54 | 퍼플렉서티 99107759632209815619164148751925248.00\n",
      "| 에폭 55 | 퍼플렉서티 54660210031095718618542279650967552.00\n",
      "| 에폭 56 | 퍼플렉서티 11595183059101088677470681918603264.00\n",
      "| 에폭 57 | 퍼플렉서티 6008782834351099271672250006241280.00\n",
      "| 에폭 58 | 퍼플렉서티 1425545577847172135692310203596800.00\n",
      "| 에폭 59 | 퍼플렉서티 318173084506424049114340957093888.00\n",
      "| 에폭 60 | 퍼플렉서티 147993353502268249769994346299392.00\n",
      "| 에폭 61 | 퍼플렉서티 89615278414191383746229674442752.00\n",
      "| 에폭 62 | 퍼플렉서티 15335189457534800694231139614720.00\n",
      "| 에폭 63 | 퍼플렉서티 4690938340198393972327670874112.00\n",
      "| 에폭 64 | 퍼플렉서티 2182936048616120610538800545792.00\n",
      "| 에폭 65 | 퍼플렉서티 625350461118736508183501602816.00\n",
      "| 에폭 66 | 퍼플렉서티 380139110880226776455684554752.00\n",
      "| 에폭 67 | 퍼플렉서티 189112269242995150739088605184.00\n",
      "| 에폭 68 | 퍼플렉서티 22461659870836451212471042048.00\n",
      "| 에폭 69 | 퍼플렉서티 7391903572834191803181694976.00\n",
      "| 에폭 70 | 퍼플렉서티 3340921946163096542483841024.00\n",
      "| 에폭 71 | 퍼플렉서티 1344645660243207562358423552.00\n",
      "| 에폭 72 | 퍼플렉서티 386224956041060004799709184.00\n",
      "| 에폭 73 | 퍼플렉서티 192074028696912932261330944.00\n",
      "| 에폭 74 | 퍼플렉서티 41627029309616620321112064.00\n",
      "| 에폭 75 | 퍼플렉서티 19240249232047404407062528.00\n",
      "| 에폭 76 | 퍼플렉서티 5893656791202349688291328.00\n",
      "| 에폭 77 | 퍼플렉서티 1345555309931323929395200.00\n",
      "| 에폭 78 | 퍼플렉서티 318333822942168098013184.00\n",
      "| 에폭 79 | 퍼플렉서티 146868527404410313113600.00\n",
      "| 에폭 80 | 퍼플렉서티 26673864771994248019968.00\n",
      "| 에폭 81 | 퍼플렉서티 45605530661920756989952.00\n",
      "| 에폭 82 | 퍼플렉서티 6753470098357413216256.00\n",
      "| 에폭 83 | 퍼플렉서티 3109410916976027500544.00\n",
      "| 에폭 84 | 퍼플렉서티 2811594710393502040064.00\n",
      "| 에폭 85 | 퍼플렉서티 1845729245836631343104.00\n",
      "| 에폭 86 | 퍼플렉서티 223791548202855399424.00\n",
      "| 에폭 87 | 퍼플렉서티 81267222720147832832.00\n",
      "| 에폭 88 | 퍼플렉서티 14165167860428861440.00\n",
      "| 에폭 89 | 퍼플렉서티 5727411452862891008.00\n",
      "| 에폭 90 | 퍼플렉서티 973381622376273280.00\n",
      "| 에폭 91 | 퍼플렉서티 618813797498607104.00\n",
      "| 에폭 92 | 퍼플렉서티 339345026572587200.00\n",
      "| 에폭 93 | 퍼플렉서티 233088913949036928.00\n",
      "| 에폭 94 | 퍼플렉서티 62360961082877632.00\n",
      "| 에폭 95 | 퍼플렉서티 10446706658842574.00\n",
      "| 에폭 96 | 퍼플렉서티 28332149799778008.00\n",
      "| 에폭 97 | 퍼플렉서티 14859155142738878.00\n",
      "| 에폭 98 | 퍼플렉서티 7173923611337491.00\n",
      "| 에폭 99 | 퍼플렉서티 1862349741015372.25\n",
      "| 에폭 100 | 퍼플렉서티 436806190072366.69\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기 (전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력\n",
    "ts = corpus[1:]  # 출력 (정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size \n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "        \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count = 1\n",
    "        \n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "         % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c46fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0934bad200ce2233862c51537af2a279b3e2fd7629fe4796e40f0bd88eed44efe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
